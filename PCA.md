# Principal Component Analysis (PCA)

## Why PCA?
Your team surveys 1,000 users about a particular mobile phone application. The survey has 7 statements, and the users are asked to indicate their opinion on a scale of 1 (very disastified) to 5 (very satisfied) about the app. The statements are:

1. The app is easy to install.
2. The app is intuitive to use.
3. The app is secure.
4. The app is quick to load.
5. The app is worth its price.
6. Support team is timely for assistance.
7. Support team does a great job of answering user's questions.

Your team collects data in a 1,000 x 7 matrix Y. Each column is for one statement. Each row corresponds to one user.

Some statements are correlated, so the team might not need all the data &rarr; PCA.

## Covariance Matrix
1. Find the mean of each column and subtract the mean from each element of the column.
2. Call the new 1,000 x 7 matrix X. Each column of X has mean zero.
3. Let K = (X^T)X, where K is the 7 x 7 matrix of covariances.
- The diagonal entries give the variances of the variables.
- The (3,4) entry gives the covariance between the 3rd and 4th statements.
- High covariance means close to a linear relationship. Zero covariance means no correlation.
- We have K^T (transpose of K) = (X^T.X)^T = X^T.X = K &rarr; K is symmetric &rarr; Spectral Theorem is applicable here.

## Eigenvectors
- K is diagonalizable with a set of orthogonal eigenvectors.
- Eigenvectors give linear combinations of the original variables. The new variables will be the ones that explain the largest variance and will be uncorrelated.
- The team wants a linear combination of 7 variables that gives the direction of the largest variance, which is also the direction of the eigenvector of K = X^T.X for the largest eigenvalue of K.
- Eigenvector of K for the second largest eigenvalue gives the direction that best captures the remaining variance and so on.
- To condense data and/or to get rid of the noise, we need only a few of the eigenvectors corresponding to the largest eigenvalues.
- The data will then be projected onto the subspace generated by these eigenvectors.

- In our mini case study, two new variables could emerge:
    - A measure of the quality of the app (a linear combination of the first 5 variables).
    - A measure of the responsivesness and helpfulness of the support team (a linear combination of the last 2 variables).
